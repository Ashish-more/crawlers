{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.enavabharat.com/feeds/latest-news.xml\n",
      "https://www.enavabharat.com/feeds/india-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/world-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/sports-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/cricket-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/football-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/tennis-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/hockey-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/other-sports-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/business-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/markets-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/economy-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/corporate-world-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/jobs-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/entertainment-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/bollywood-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/hollywood-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/celebrity-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/movies-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/television-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/lifestyle-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/vastu-astrology-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/health-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/fashion-beauty-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/travel-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/religion-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/food-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/relationships-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/technology-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/science-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/gadgets-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/mobiles-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/internet.xml\n",
      "https://www.enavabharat.com/feeds/education-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/automobile-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/cars-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/bikes-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/gallery.xml\n",
      "https://www.enavabharat.com/feeds/photos.xml\n",
      "https://www.enavabharat.com/feeds/videos.xml\n",
      "https://www.enavabharat.com/feeds/state-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/maharashtra-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/mumbai-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/nagpur-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/pune-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/nashik-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/aurangabad-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/amravati-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/chandrapur-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/akola-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/bhandara-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/gondia-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/gadchiroli-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/wardha-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/yavatmal-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/thane-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/buldhana-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/washim-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/madhya-pradesh-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/bhopal-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/chhattisgarh-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/odisha-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/uttar-pradesh-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/north-india-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/delhi-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/other-states-news-hindi.xml\n",
      "https://www.enavabharat.com/feeds/blogs.xml\n",
      "https://www.enavabharat.com/feeds/special-coverage.xml\n",
      "https://www.enavabharat.com/feeds/aaj-ki-khas-khabar.xml\n",
      "https://www.enavabharat.com/feeds/editorial.xml\n",
      "https://www.enavabharat.com/feeds/nishanebaaz.xml\n",
      "https://www.enavabharat.com/feeds/aaj-ka-itihas.xml\n",
      "https://www.enavabharat.com/feeds/cartoon.xml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os \n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime,timedelta\n",
    "from datetime import date\n",
    "import re\n",
    "import sys\n",
    "import urllib, urllib.request, urllib.parse\n",
    "import random\n",
    "from scrawl import *\n",
    "\n",
    "# Date and time\n",
    "start_time = time.time()\n",
    "current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "created_on = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# client_id = sys.argv[1]\n",
    "client_id = '5f69d22ef472d6646f577fa6'  # Europe\n",
    "site = 'enavabharat_com'\n",
    "c = Crawl()  # creating object\n",
    "cl_data = dashboard['core_web_india']\n",
    "# create directories to store logs.\n",
    "log_path = c.create_directories(project_path, client_id, site)\n",
    "\n",
    "# create image directories\n",
    "image_directory = c.create_image_directories(project_path)\n",
    "\n",
    "# logger\n",
    "logger = log_func(log_path, created_on, current_time)\n",
    "logger.info(\"Process Started ...\\n\")\n",
    "\n",
    "# initialize variables\n",
    "skipped_due_to_headline = 0\n",
    "skipped_due_to_content = 0\n",
    "skipped_due_to_date = 0\n",
    "missing_overall_tonality = 0\n",
    "no_of_data = 0\n",
    "duplicate_data = 0  \n",
    "unable_to_fetch_url = 0\n",
    "unable_to_fetch_rss_page = 0\n",
    "publish_source = 'enavabharat.com'\n",
    "country = 'India'\n",
    "language = 'Hindi'\n",
    "images_path = []\n",
    "\n",
    "rss_pages = c.download_page('https://enavabharat.com/feeds/')\n",
    "rss_pages = c.scrap('<div\\s*class=\"page_body\">(.*?)<footer\\s*class=\"footer\">', rss_pages)\n",
    "\n",
    "\n",
    "for _ in rss_pages.split('href=')[1:]:\n",
    "    \n",
    "    rss_url = c.scrap('\"(.*?)\"', _)\n",
    "    url = c.download_page(rss_url)\n",
    "\n",
    "    if url.startswith('Unable to fetch'):\n",
    "        logger.info(url) # writes error message with error code\n",
    "        unable_to_fetch_rss_page += 1\n",
    "        continue   \n",
    "        \n",
    "    for i in url.split('<item>')[1:]:\n",
    "\n",
    "        # source_link\n",
    "        source_link = c.scrap('<link>(.*?)</link>', i)\n",
    "        source_link = source_link.replace(\"<![CDATA[\", \"\").replace(\"]]>\", \"\")\n",
    "        \n",
    "        # handle duplicates\n",
    "        source_link_query = {'source_link':source_link}\n",
    "        dic = cl_data.find_one(source_link_query,{'source_link': 1}) \n",
    "        if dic:\n",
    "            duplicate_data += 1\n",
    "            continue          \n",
    "                \n",
    "        time.sleep(random.randint(1,3))\n",
    "        \n",
    "        page = c.download_page(source_link)\n",
    "        if page.startswith('Unable to fetch'):\n",
    "                logger.info(page) # writes error message with error code\n",
    "                unable_to_fetch_url += 1\n",
    "                continue  \n",
    "        # source_headline\n",
    "        source_headline = c.scrap('<title>(.*?)</title>', page)\n",
    "        source_headline = source_headline.replace(\"<![CDATA[\", \"\").replace(\"]]>\", \"\")\n",
    "        # skip if headline not found\n",
    "        if not source_headline:\n",
    "            logger.info(f'Skipping due to headline {source_link}\\n')\n",
    "            skipped_due_to_headline += 1\n",
    "            continue\n",
    "\n",
    "        logger.info(f'Fetching {source_link}\\n')\n",
    "                   \n",
    "         # Date and time\n",
    "        pub_date, publish_time = '', ''\n",
    "\n",
    "        try:\n",
    "            date_time_str = c.scrap('<pubDate>\\w+,\\s+(.*?) \\+', i)\n",
    "            date_time_obj = datetime.strptime(date_time_str, '%d %b %Y %H:%M:%S')\n",
    "            # There is no time difference between India and Sri Lanka\n",
    "            ist_date_time = date_time_obj - timedelta(hours = 5,minutes = 30)  \n",
    "            ist_date_time = ist_date_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "            pub_date = ist_date_time[:10]\n",
    "            publish_time = ist_date_time[11:]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # skip null date\n",
    "        if not pub_date:\n",
    "            logger.info(f'Skipping due to date {source_link}\\n')\n",
    "            skipped_due_to_date += 1\n",
    "            continue\n",
    "            \n",
    "        # break if date is not today's date\n",
    "        if pub_date != created_on:\n",
    "            break    \n",
    "                    \n",
    "        # journalist   \n",
    "        journalist = c.scrap('<div\\s*class=\"author\">(.*?)</a>', page)\n",
    "        journalist = c.strip_html(journalist)\n",
    "        if not journalist: journalist = 'NA'\n",
    "           \n",
    "        # source_content          \n",
    "        source_content = c.scrap('<h2\\s*class=\"subtitle\">(.*?)<div\\s*class=\"article-footer\"> ', page)\n",
    "        source_content = c.strip_html(source_content)\n",
    "        \n",
    "         # current date and time \n",
    "        harvest_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "        # temp link\n",
    "        temp_link = source_link\n",
    "\n",
    "        # headline and content \n",
    "        headline = source_headline\n",
    "        content = source_content\n",
    "\n",
    "        # overall_tonality\n",
    "        overall_tonality = ''\n",
    "\n",
    "        # word count\n",
    "        word_count = len((source_headline + ' ' + source_content).split())\n",
    "\n",
    "        html_content = ''\n",
    "\n",
    "        # image_urls\n",
    "        image_urls = []\n",
    "\n",
    "        # storing the above data in a dictionary\n",
    "        clientdata ={\n",
    "                        \"client_master\" : client_id, \n",
    "                        \"articleid\":client_id,\n",
    "                        \"medium\":'Web' ,\n",
    "                        \"searchkeyword\":[],\n",
    "                        \"entityname\" : [] ,\n",
    "                        \"process_flage\":\"1\",\n",
    "                        \"na_flage\":\"0\",\n",
    "                        \"na_reason\":\"\",\n",
    "                        \"qc_by\":\"\",\n",
    "                        \"qc_on\":\"\",\n",
    "                        \"location\":\"\",\n",
    "                        \"spokeperson\":\"\",\n",
    "                        \"quota\":\"\",\n",
    "                        \"overall_topics\":\"\",\n",
    "                        \"person\":\"\",\n",
    "                        \"overall_entites\":\"\",\n",
    "                        \"overall_tonality\": overall_tonality,\n",
    "                        \"overall_wordcount\":word_count,\n",
    "                        \"article_subjectivity\":\"\",\n",
    "                        \"article_summary\":\"\",\n",
    "                        \"pub_date\":pub_date,\n",
    "                        \"publish_time\":publish_time,\n",
    "                        \"harvest_time\":harvest_time,\n",
    "                        \"temp_link\":temp_link,\n",
    "                        \"publish_source\": publish_source,\n",
    "                        \"programme\":'null',\n",
    "                        \"feed_class\":\"News\",\n",
    "                        \"publishing_platform\":\"\",\n",
    "                        \"klout_score\":\"\",\n",
    "                        \"journalist\":journalist,\n",
    "                        \"headline\":headline,\n",
    "                        \"content\":content,\n",
    "                        \"source_headline\":source_headline,\n",
    "                        \"source_content\":source_content,\n",
    "                        \"language\":language,\n",
    "                        \"presence\":'null',\n",
    "                        \"clip_type\":'null',\n",
    "                        \"prog_slot\":'null',\n",
    "                        \"op_ed\":'0',\n",
    "                        \"location_mention\":'',\n",
    "                        \"source_link\":source_link,\n",
    "                        \"author_contact\":'',\n",
    "                        \"author_emailid\":'',\n",
    "                        \"author_url\":'',\n",
    "                        \"city\":'',\n",
    "                        \"state\":'',\n",
    "                        \"country\":country,\n",
    "                        \"source\":publish_source,\n",
    "                        \"foot_fall\":'',\n",
    "                        \"created_on\":created_on,\n",
    "                        \"active\":'1',\n",
    "                        'crawl_flag':2,\n",
    "                        \"images_path\":images_path,\n",
    "                        \"html_content\":html_content\n",
    "                    } \n",
    "\n",
    "        cl_data.insert_one(clientdata)  \n",
    "        no_of_data += 1\n",
    "        \n",
    "logger.info('Iteration complete\\n')   \n",
    "\n",
    "logger.info(f'Number of data: {no_of_data}\\n')\n",
    "logger.info(f'Duplicate data: {duplicate_data}\\n')\n",
    "logger.info(f'Unable to fetch rss url: {unable_to_fetch_rss_page}\\n')\n",
    "logger.info(f'Unable to fetch article url: {unable_to_fetch_url}\\n')\n",
    "logger.info(f'Skipped due to headline: {skipped_due_to_headline}\\n')\n",
    "logger.info(f'Skipped due to content: {skipped_due_to_content}\\n')\n",
    "logger.info(f'Skipped due to date: {skipped_due_to_date}\\n')\n",
    "logger.info(f'Processing finished in {time.time() - start_time} seconds.\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
